{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "283aac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fab9d8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3000, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>NumWebPurchases</th>\n",
       "      <th>TotalChildren</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.883733</td>\n",
       "      <td>1.230379</td>\n",
       "      <td>-0.807246</td>\n",
       "      <td>1.358131</td>\n",
       "      <td>1.421400</td>\n",
       "      <td>0.874273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.820820</td>\n",
       "      <td>-1.224651</td>\n",
       "      <td>-0.021877</td>\n",
       "      <td>-1.393109</td>\n",
       "      <td>-0.845948</td>\n",
       "      <td>-0.003805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.582383</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.738953</td>\n",
       "      <td>0.623531</td>\n",
       "      <td>1.648135</td>\n",
       "      <td>-0.881883</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.448523</td>\n",
       "      <td>1.230379</td>\n",
       "      <td>1.992767</td>\n",
       "      <td>-0.850347</td>\n",
       "      <td>-0.845948</td>\n",
       "      <td>1.752351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.197684</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-1.182858</td>\n",
       "      <td>0.960418</td>\n",
       "      <td>1.874870</td>\n",
       "      <td>0.874273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Income   Kidhome   Recency  MntWines  NumWebPurchases  TotalChildren  \\\n",
       "0  1.883733  1.230379 -0.807246  1.358131         1.421400       0.874273   \n",
       "1 -0.820820 -1.224651 -0.021877 -1.393109        -0.845948      -0.003805   \n",
       "2  0.582383  0.002864 -0.738953  0.623531         1.648135      -0.881883   \n",
       "3 -0.448523  1.230379  1.992767 -0.850347        -0.845948       1.752351   \n",
       "4  1.197684  0.002864 -1.182858  0.960418         1.874870       0.874273   \n",
       "\n",
       "   Response  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1Ô∏è‚É£ Load Preprocessed Data\n",
    "# ---------------------------\n",
    "df = pd.read_csv('../Data/preprocessed.csv')\n",
    "print('Shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47d374bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (2400, 6) Test: (600, 6)\n"
     ]
    }
   ],
   "source": [
    "# 2Ô∏è‚É£ Features and Target\n",
    "# ---------------------------\n",
    "X = df.drop('Response', axis=1)\n",
    "y = df['Response']\n",
    "\n",
    "# Train/Test Split (again, to be sure)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print('Train:', X_train.shape, 'Test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1515558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£ Initialize Models\n",
    "# ---------------------------\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3fff703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Logistic Regression Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       300\n",
      "           1       1.00      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00       600\n",
      "   macro avg       1.00      1.00      1.00       600\n",
      "weighted avg       1.00      1.00      1.00       600\n",
      "\n",
      "Confusion Matrix:\n",
      "[[300   0]\n",
      " [  0 300]]\n",
      "\n",
      "‚úÖ SVM Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       300\n",
      "           1       1.00      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00       600\n",
      "   macro avg       1.00      1.00      1.00       600\n",
      "weighted avg       1.00      1.00      1.00       600\n",
      "\n",
      "Confusion Matrix:\n",
      "[[300   0]\n",
      " [  0 300]]\n",
      "\n",
      "‚úÖ Random Forest Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       300\n",
      "           1       1.00      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00       600\n",
      "   macro avg       1.00      1.00      1.00       600\n",
      "weighted avg       1.00      1.00      1.00       600\n",
      "\n",
      "Confusion Matrix:\n",
      "[[300   0]\n",
      " [  0 300]]\n",
      "\n",
      "‚úÖ AdaBoost Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       300\n",
      "           1       1.00      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00       600\n",
      "   macro avg       1.00      1.00      1.00       600\n",
      "weighted avg       1.00      1.00      1.00       600\n",
      "\n",
      "Confusion Matrix:\n",
      "[[300   0]\n",
      " [  0 300]]\n",
      "\n",
      "‚úÖ Gradient Boosting Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       300\n",
      "           1       1.00      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00       600\n",
      "   macro avg       1.00      1.00      1.00       600\n",
      "weighted avg       1.00      1.00      1.00       600\n",
      "\n",
      "Confusion Matrix:\n",
      "[[300   0]\n",
      " [  0 300]]\n"
     ]
    }
   ],
   "source": [
    "# 4Ô∏è‚É£ Train & Evaluate\n",
    "# ---------------------------\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1-Score\": f1\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n‚úÖ {name} Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e48cbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Model Comparison:\n",
      "                 Model  Accuracy  Precision  Recall  F1-Score\n",
      "0  Logistic Regression       1.0        1.0     1.0       1.0\n",
      "1                  SVM       1.0        1.0     1.0       1.0\n",
      "2        Random Forest       1.0        1.0     1.0       1.0\n",
      "3             AdaBoost       1.0        1.0     1.0       1.0\n",
      "4    Gradient Boosting       1.0        1.0     1.0       1.0\n"
     ]
    }
   ],
   "source": [
    "# 5Ô∏è‚É£ Compare All Models\n",
    "# ---------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "print('\\nüìä Model Comparison:')\n",
    "print(results_df.sort_values(by=\"F1-Score\", ascending=False).reset_index(drop=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

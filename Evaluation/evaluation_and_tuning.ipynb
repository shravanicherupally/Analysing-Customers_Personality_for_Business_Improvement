{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e9ff2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53bee793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (2400, 6) Test: (600, 6)\n"
     ]
    }
   ],
   "source": [
    "# 1Ô∏è‚É£ Load Preprocessed Data\n",
    "# ---------------------------\n",
    "df = pd.read_csv('../Data/preprocessed.csv')\n",
    "\n",
    "X = df.drop('Response', axis=1)\n",
    "y = df['Response']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print('Train:', X_train.shape, 'Test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c72cb837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£ Define Param Grids\n",
    "# ---------------------------\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'solver': ['liblinear', 'lbfgs']\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 5, 10]\n",
    "    },\n",
    "    \"AdaBoost\": {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.5, 1.0, 1.5]\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.05, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eee72ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Tuning Logistic Regression ...\n",
      "‚úÖ Logistic Regression Tuned ‚Üí F1-Score: 1.0000\n",
      "\n",
      "üîç Tuning SVM ...\n",
      "‚úÖ SVM Tuned ‚Üí F1-Score: 1.0000\n",
      "\n",
      "üîç Tuning Random Forest ...\n",
      "‚úÖ Random Forest Tuned ‚Üí F1-Score: 1.0000\n",
      "\n",
      "üîç Tuning AdaBoost ...\n",
      "‚úÖ AdaBoost Tuned ‚Üí F1-Score: 1.0000\n",
      "\n",
      "üîç Tuning Gradient Boosting ...\n",
      "‚úÖ Gradient Boosting Tuned ‚Üí F1-Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 3Ô∏è‚É£ Run GridSearchCV & Evaluate Tuned Models\n",
    "# ---------------------------\n",
    "base_models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_params = {}\n",
    "\n",
    "for name, model in base_models.items():\n",
    "    print(f\"\\nüîç Tuning {name} ...\")\n",
    "    grid = GridSearchCV(model, param_grids[name], cv=5, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "    best_params[name] = grid.best_params_\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1-Score\": f1\n",
    "    })\n",
    "    \n",
    "    print(f\"‚úÖ {name} Tuned ‚Üí F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb9dba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Tuned Models Comparison:\n",
      "                 Model  Accuracy  Precision  Recall  F1-Score\n",
      "0  Logistic Regression       1.0        1.0     1.0       1.0\n",
      "1                  SVM       1.0        1.0     1.0       1.0\n",
      "2        Random Forest       1.0        1.0     1.0       1.0\n",
      "3             AdaBoost       1.0        1.0     1.0       1.0\n",
      "4    Gradient Boosting       1.0        1.0     1.0       1.0\n"
     ]
    }
   ],
   "source": [
    "# 4Ô∏è‚É£ Show Final Comparison Table\n",
    "# ---------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nüìä Tuned Models Comparison:\")\n",
    "print(results_df.sort_values(by=\"F1-Score\", ascending=False).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e0b8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Saved: tuned_models_comparison.csv\n",
      "‚úÖ Saved: best_hyperparameters.csv\n"
     ]
    }
   ],
   "source": [
    "# 5Ô∏è‚É£ Save Comparison & Best Params\n",
    "# ---------------------------\n",
    "results_df.to_csv('../Evaluation/tuned_models_comparison.csv', index=False)\n",
    "print(\"\\n‚úÖ Saved: tuned_models_comparison.csv\")\n",
    "\n",
    "params_df = pd.DataFrame(list(best_params.items()), columns=['Model', 'BestParams'])\n",
    "params_df.to_csv('../Evaluation/best_hyperparameters.csv', index=False)\n",
    "print(\"‚úÖ Saved: best_hyperparameters.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
